/**
 * LLM æ¥å£ç±»
 * è´Ÿè´£ä¸è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’
 * ä¸“æ³¨äºçº¯ç²¹çš„è¯­è¨€æ¨¡å‹è¯·æ±‚ï¼Œä¸å¤„ç†æ¶ˆæ¯ä¼˜åŒ–
 */

import OpenAI from 'openai';
import { promises as fs } from 'fs';
import { Message, ToolChoice, Role } from '../schema/index.js';
import { config } from '../utils/config.js';
import { Logger } from '../utils/logger.js';

// LLM å“åº”æ¥å£
interface LLMResponse {
  content: string | null;
  tool_calls?: any[];
  usage?: any;
}

// ä»»åŠ¡ç±»å‹æšä¸¾
export enum TaskType {
  DEFAULT = 'default',
  CODING = 'coding',
  VISION = 'vision',
  PLANNING = 'planning',
  ANALYSIS = 'analysis',
}

// ä»»åŠ¡ç±»å‹åˆ°æ¨¡å‹é…ç½®çš„æ˜ å°„
const TASK_TO_MODEL_CONFIG: Record<TaskType, string> = {
  [TaskType.DEFAULT]: 'default',
  [TaskType.CODING]: 'coder',
  [TaskType.VISION]: 'vision',
  [TaskType.PLANNING]: 'default',
  [TaskType.ANALYSIS]: 'default',
};

// é‡è¯•é…ç½®
interface RetryConfig {
  enabled: boolean;
  maxRetries: number;
  initialDelayMs: number;
  maxDelayMs: number;
  backoffMultiplier: number;
}

const DEFAULT_RETRY_CONFIG: RetryConfig = {
  enabled: true,
  maxRetries: 3,
  initialDelayMs: 6000,
  maxDelayMs: 60000,
  backoffMultiplier: 2,
};

/**
 * LLM ç±»
 * å¤„ç†ä¸è¯­è¨€æ¨¡å‹çš„äº¤äº’ï¼Œä¸“æ³¨äºçº¯ç²¹çš„æ¨¡å‹è¯·æ±‚
 */
export class LLM {
  private client: OpenAI;
  private logger: Logger;
  private configName: string;
  private retryConfig: RetryConfig;

  constructor(configName: string = 'default', retryConfig?: Partial<RetryConfig>) {
    this.configName = configName;
    this.logger = new Logger('LLM');
    this.retryConfig = { ...DEFAULT_RETRY_CONFIG, ...retryConfig };

    // è·å– LLM é…ç½®
    const llmConfig = config.getLLMConfig(configName);

    // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    this.client = new OpenAI({
      apiKey: llmConfig.api_key,
      baseURL: llmConfig.base_url,
    });
  }

  /**
   * æ ¹æ®ä»»åŠ¡ç±»å‹åˆ›å»º LLM å®ä¾‹
   */
  static createForTask(taskType: TaskType, retryConfig?: Partial<RetryConfig>): LLM {
    const configName = TASK_TO_MODEL_CONFIG[taskType];
    return new LLM(configName, retryConfig);
  }

  /**
   * è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
   */
  getModelInfo(): { configName: string; model: string; baseUrl: string } {
    const llmConfig = config.getLLMConfig(this.configName);
    return {
      configName: this.configName,
      model: llmConfig.model,
      baseUrl: llmConfig.base_url,
    };
  }

  /**
   * ç¡®ä¿æ¶ˆæ¯æœ‰æ•ˆæ€§ï¼ˆè‡³å°‘ä¸€æ¡éç³»ç»Ÿæ¶ˆæ¯ï¼‰
   */
  private ensureValidMessages(messages: Message[]): Message[] {
    const hasNonSystemMessage = messages.some((msg) => msg.role !== Role.SYSTEM);

    let validatedMessages = messages;

    // é¦–å…ˆéªŒè¯å·¥å…·è°ƒç”¨å®Œæ•´æ€§ï¼Œé˜²æ­¢Claude APIé”™è¯¯
    validatedMessages = this.validateToolCallPairs(validatedMessages);

    if (hasNonSystemMessage) {
      return validatedMessages;
    }

    // åˆ›å»ºé»˜è®¤æ¶ˆæ¯
    const defaultMessage = new Message({
      role: Role.USER,
      content: 'è¯·ç»§ç»­å¯¹è¯',
    });

    this.logger.warn('No non-system messages found, adding default user message');
    return [...validatedMessages, defaultMessage];
  }

  /**
   * éªŒè¯å·¥å…·è°ƒç”¨é…å¯¹å®Œæ•´æ€§ - LLMæœ€ç»ˆå®‰å…¨æ£€æŸ¥
   * ç¡®ä¿å‘é€ç»™Claudeçš„æ¶ˆæ¯ä¸­æ¯ä¸ªtoolUseéƒ½æœ‰å¯¹åº”çš„toolResult
   */
  private validateToolCallPairs(messages: Message[]): Message[] {
    const result: Message[] = [];
    const pendingToolCalls = new Map<string, Message>();
    const processedToolResults = new Set<string>();

    for (const message of messages) {
      if (message.tool_calls && message.tool_calls.length > 0) {
        // å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼šè®°å½•å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨
        const validToolCalls = message.tool_calls.filter((call) => call.id && call.function?.name);

        if (validToolCalls.length > 0) {
          // è®°å½•è¿™äº›å·¥å…·è°ƒç”¨ï¼Œç­‰å¾…åŒ¹é…çš„ç»“æœ
          validToolCalls.forEach((call) => {
            pendingToolCalls.set(call.id, message);
          });

          // åªä¿ç•™æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨
          if (validToolCalls.length === message.tool_calls.length) {
            result.push(message);
          } else {
            result.push(new Message({
              role: message.role,
              content: message.content,
              tool_calls: validToolCalls,
            }));
          }
        } else {
          // æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ï¼Œåªä¿ç•™å†…å®¹
          if (message.content) {
            result.push(new Message({
              role: message.role,
              content: message.content,
            }));
          }
        }
      } else if (message.tool_call_id) {
        // å·¥å…·ç»“æœæ¶ˆæ¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å·¥å…·è°ƒç”¨
        if (pendingToolCalls.has(message.tool_call_id) && !processedToolResults.has(message.tool_call_id)) {
          result.push(message);
          processedToolResults.add(message.tool_call_id);
        } else {
          this.logger.warn(`Removing orphaned or duplicate tool result: ${message.tool_call_id}`);
        }
      } else {
        // æ™®é€šæ¶ˆæ¯ï¼Œç›´æ¥æ·»åŠ 
        result.push(message);
      }
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰æœªé…å¯¹çš„å·¥å…·è°ƒç”¨
    const unpairedToolCalls = Array.from(pendingToolCalls.keys()).filter(
      (id) => !processedToolResults.has(id)
    );

    if (unpairedToolCalls.length > 0) {
      this.logger.warn(`Found ${unpairedToolCalls.length} unpaired tool calls, removing them`);

      // ç§»é™¤æ²¡æœ‰å¯¹åº”ç»“æœçš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
      const finalResult: Message[] = [];
      for (const message of result) {
        if (message.tool_calls && message.tool_calls.length > 0) {
          const pairedToolCalls = message.tool_calls.filter((call) =>
            !unpairedToolCalls.includes(call.id)
          );

          if (pairedToolCalls.length > 0) {
            finalResult.push(new Message({
              role: message.role,
              content: message.content,
              tool_calls: pairedToolCalls,
            }));
          } else if (message.content) {
            finalResult.push(new Message({
              role: message.role,
              content: message.content,
            }));
          }
        } else {
          finalResult.push(message);
        }
      }

      return finalResult;
    }

    if (result.length !== messages.length) {
      this.logger.debug(`Final tool call validation: ${messages.length} -> ${result.length} messages`);
    }

    return result;
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private async delay(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
   */
  private isRetryableError(error: any): boolean {
    if (!error.status) return false;

    // 429 (Rate Limit), 500, 502, 503, 504 æ˜¯å¯é‡è¯•çš„é”™è¯¯
    const retryableStatuses = [429, 500, 502, 503, 504];
    return retryableStatuses.includes(error.status);
  }

  /**
   * è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´
   */
  private calculateRetryDelay(attempt: number): number {
    const delay =
      this.retryConfig.initialDelayMs * Math.pow(this.retryConfig.backoffMultiplier, attempt);
    return Math.min(delay, this.retryConfig.maxDelayMs);
  }

  /**
   * å‘é€è¯·æ±‚åˆ°è¯­è¨€æ¨¡å‹
   */
  private async sendRequest(options: {
    messages: Message[];
    systemMsgs?: Message[];
    tools?: any[];
    toolChoice?: ToolChoice;
    currentQuery?: string;
  }): Promise<LLMResponse> {
    const startTime = Date.now();
    let lastError: any;

    // æ‰“å°LLMè°ƒç”¨å¼€å§‹æ—¥å¿—
    const llmConfig = config.getLLMConfig(this.configName);
    this.logger.info(`ğŸš€ å¼€å§‹LLMè°ƒç”¨ - æ¨¡å‹: ${llmConfig.model}, é…ç½®: ${this.configName}`);
    this.logger.info(
      `ğŸ“ è¾“å…¥æ¶ˆæ¯æ•°é‡: ${options.messages.length}, ç³»ç»Ÿæ¶ˆæ¯æ•°é‡: ${options.systemMsgs?.length || 0}`
    );
    this.logger.info(
      `ğŸ› ï¸ å·¥å…·æ•°é‡: ${options.tools?.length || 0}, å·¥å…·é€‰æ‹©æ¨¡å¼: ${options.toolChoice || 'auto'}`
    );

    // æ‰“å°ç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡æ¶ˆæ¯çš„æ‘˜è¦
    if (options.messages.length > 0) {
      // const firstMsg = options.messages[0];
      const lastMsg = options.messages[options.messages.length - 1];

      this.logger.info(
        `ğŸ“¤ æœ€åä¸€æ¡æ¶ˆæ¯: ${lastMsg.role} - ${(lastMsg.content || '').substring(0, 100)}${(lastMsg.content || '').length > 100 ? '...' : ''}`
      );
    }

    for (let attempt = 0; attempt <= this.retryConfig.maxRetries; attempt++) {
      try {
        // å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œéœ€è¦ç­‰å¾…
        if (attempt > 0 && this.retryConfig.enabled) {
          const delayMs = this.calculateRetryDelay(attempt - 1);
          this.logger.warn(
            `Rate limit hit, retrying in ${delayMs}ms (attempt ${attempt + 1}/${this.retryConfig.maxRetries + 1})`
          );
          await this.delay(delayMs);
        }

        // åˆå¹¶ç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯
        const allMessages = [...(options.systemMsgs || []), ...options.messages];

        // ç¡®ä¿æ¶ˆæ¯æœ‰æ•ˆæ€§
        // const validatedMessages = this.ensureValidMessages(allMessages);

        // å‡†å¤‡æ¶ˆæ¯æ ¼å¼
        const formattedMessages = allMessages.map((msg: Message) => ({
          role: msg.role as any, // ç±»å‹è½¬æ¢ä»¥åŒ¹é… OpenAI API
          content: msg.content,
          ...(msg.tool_calls && { tool_calls: msg.tool_calls }),
          ...(msg.tool_call_id && {
            tool_call_id: msg.tool_call_id,
            tool_result: msg.content,
            role: 'user',
            // content: [
            //   {
            //     type: 'tool_result',
            //     tool_use_id: msg.tool_call_id,
            //     content: [{ type: 'text', text: msg.content }],
            //   },
            // ],
            // content: [
            //   {
            //     toolResult: {
            //       content: [{ text: msg.content }],
            //       toolUseId: msg.tool_call_id,
            //     },
            //   },
            // ],
          }),
          ...(msg.name && { name: msg.name }),
        }));

        // æ‰“å°è¯·æ±‚å‚æ•°
        this.logger.info(`ğŸ“¡ å‘é€LLMè¯·æ±‚ - å°è¯•æ¬¡æ•°: ${attempt + 1}`);
        this.logger.info(
          `ğŸ”§ è¯·æ±‚å‚æ•°: model=${llmConfig.model}, temperature=${llmConfig.temperature}, max_tokens=${llmConfig.max_tokens}`
        );

        // å‘é€è¯·æ±‚
        const response = await this.client.chat.completions.create({
          model: llmConfig.model,
          messages: formattedMessages as any, // ç±»å‹è½¬æ¢ä»¥åŒ¹é… OpenAI API
          tools: options.tools,
          tool_choice: options.toolChoice,
          temperature: llmConfig.temperature,
          max_tokens: llmConfig.max_tokens,
        });

        const llmResponse: LLMResponse = {
          content: response.choices[0].message.content,
          tool_calls: response.choices[0].message.tool_calls,
          usage: response.usage,
        };

        const executionTime = Date.now() - startTime;

        // æ‰“å°å“åº”ç»“æœ
        this.logger.info(`âœ… LLMè°ƒç”¨æˆåŠŸ - æ‰§è¡Œæ—¶é—´: ${executionTime}ms`);
        this.logger.info(`ğŸ“„ å“åº”å†…å®¹é•¿åº¦: ${(llmResponse.content || '').length} å­—ç¬¦`);
        this.logger.info(`ğŸ› ï¸ å·¥å…·è°ƒç”¨æ•°é‡: ${llmResponse.tool_calls?.length || 0}`);

        if (llmResponse.tool_calls && llmResponse.tool_calls.length > 0) {
          this.logger.info(
            `ğŸ”§ å·¥å…·è°ƒç”¨è¯¦æƒ…: ${llmResponse.tool_calls.map((call) => call.function.name).join(', ')}`
          );
        }

        if (llmResponse.usage) {
          this.logger.info(
            `ğŸ“Š Tokenä½¿ç”¨æƒ…å†µ: prompt_tokens=${llmResponse.usage.prompt_tokens}, completion_tokens=${llmResponse.usage.completion_tokens}, total_tokens=${llmResponse.usage.total_tokens}`
          );
        }

        // è®°å½•è¯¦ç»†ä»»åŠ¡æ—¥å¿—
        await this.logTaskDetails(options, llmResponse, undefined, executionTime);

        // è®°å½•ç®€å•ä½¿ç”¨æ—¥å¿—
        await this.logUsage(llmResponse, formattedMessages.length);

        return llmResponse;
      } catch (error: any) {
        lastError = error;
        const executionTime = Date.now() - startTime;

        // æ‰“å°é”™è¯¯ä¿¡æ¯
        this.logger.error(
          `âŒ LLMè°ƒç”¨å¤±è´¥ - å°è¯•æ¬¡æ•°: ${attempt + 1}, æ‰§è¡Œæ—¶é—´: ${executionTime}ms`
        );
        this.logger.error(`ğŸš¨ é”™è¯¯è¯¦æƒ…: ${error.message || String(error)}`);
        this.logger.error(
          `ğŸ” é”™è¯¯ç±»å‹: ${error.constructor.name}, çŠ¶æ€ç : ${error.status || 'N/A'}`
        );

        // å¦‚æœæ˜¯å¯é‡è¯•çš„é”™è¯¯ä¸”è¿˜æœ‰é‡è¯•æ¬¡æ•°
        if (
          this.retryConfig.enabled &&
          this.isRetryableError(error) &&
          attempt < this.retryConfig.maxRetries
        ) {
          this.logger.warn(
            `ğŸ”„ å¯é‡è¯•é”™è¯¯ï¼Œå‡†å¤‡é‡è¯• (attempt ${attempt + 1}/${this.retryConfig.maxRetries + 1}): ${error.message || error}`
          );
          continue;
        }

        // å¦‚æœä¸å¯é‡è¯•æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè®°å½•é”™è¯¯å¹¶æŠ›å‡º
        await this.logTaskDetails(options, undefined, error, executionTime);

        this.logger.error(
          `ğŸ’¥ LLMè¯·æ±‚æœ€ç»ˆå¤±è´¥ï¼Œå·²å°è¯• ${attempt + 1} æ¬¡: ${error.message || error}`
        );
        throw error;
      }
    }

    // ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†ç±»å‹å®‰å…¨
    throw lastError || new Error('Unknown error occurred');
  }

  /**
   * è®°å½•è¯¦ç»†çš„ä»»åŠ¡æ—¥å¿—åˆ° task_log.jsonl
   */
  private async logTaskDetails(
    input: {
      messages: Message[];
      systemMsgs?: Message[];
      tools?: any[];
      toolChoice?: ToolChoice;
      currentQuery?: string;
    },
    response?: LLMResponse,
    error?: any,
    executionTime?: number
  ): Promise<void> {
    try {
      const logDir = './.manus';
      const logFile = `${logDir}/task_log.jsonl`;

      // ç¡®ä¿ç›®å½•å­˜åœ¨
      try {
        await fs.mkdir(logDir, { recursive: true });
      } catch (mkdirError) {
        // ç›®å½•å¯èƒ½å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
      }

      const logEntry = {
        timestamp: new Date().toISOString(),
        type: 'llm_call',
        model: this.getModelInfo(),
        input: {
          systemMessages:
            input.systemMsgs?.map((msg) => ({
              role: msg.role,
              content: msg.content,
              ...(msg.tool_calls && { tool_calls: msg.tool_calls }),
              ...(msg.tool_call_id && { tool_call_id: msg.tool_call_id }),
              ...(msg.name && { name: msg.name }),
            })) || [],
          messages: input.messages.map((msg) => ({
            role: msg.role,
            content: msg.content,
            ...(msg.tool_calls && { tool_calls: msg.tool_calls }),
            ...(msg.tool_call_id && { tool_call_id: msg.tool_call_id }),
            ...(msg.name && { name: msg.name }),
          })),
          tools: input.tools || [],
          toolChoice: input.toolChoice,
          currentQuery: input.currentQuery,
          totalInputMessages: (input.systemMsgs?.length || 0) + input.messages.length,
        },
        ...(response && {
          output: {
            content: response.content,
            tool_calls: response.tool_calls || [],
            usage: response.usage,
          },
        }),
        ...(error && {
          error: {
            message: error.message || String(error),
            status: error.status,
            type: error.constructor.name,
          },
        }),
        executionTime: executionTime,
        success: !error,
      };

      await fs.appendFile(logFile, JSON.stringify(logEntry) + '\n', 'utf-8');
    } catch (logError) {
      this.logger.error(`è®°å½•ä»»åŠ¡æ—¥å¿—å¤±è´¥: ${logError}`);
    }
  }

  /**
   * è®°å½•ä½¿ç”¨æƒ…å†µ
   */
  private async logUsage(response: LLMResponse, messageCount: number): Promise<void> {
    if (response.usage) {
      try {
        const logDir = './.manus';
        const logFile = `${logDir}/token_usage.jsonl`;

        // ç¡®ä¿ç›®å½•å­˜åœ¨
        try {
          await fs.mkdir(logDir, { recursive: true });
        } catch (mkdirError) {
          // ç›®å½•å¯èƒ½å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
        }

        const logObj = {
          timestamp: new Date().toISOString(),
          model: config.getLLMConfig(this.configName).model,
          messageCount,
          ...response.usage,
        };

        await fs.appendFile(logFile, JSON.stringify(logObj) + '\n', 'utf-8');
      } catch (error) {
        this.logger.error(`è®°å½•ä½¿ç”¨æƒ…å†µå¤±è´¥: ${error}`);
      }
    }
  }

  /**
   * å‘è¯­è¨€æ¨¡å‹å‘é€æ™®é€šè¯·æ±‚
   */
  async ask(options: {
    messages: Message[];
    systemMsgs?: Message[];
    currentQuery?: string;
  }): Promise<string> {
    const response = await this.sendRequest(options);
    return response.content || '';
  }

  /**
   * å‘è¯­è¨€æ¨¡å‹å‘é€å·¥å…·è°ƒç”¨è¯·æ±‚
   */
  async askTool(options: {
    messages: Message[];
    systemMsgs?: Message[];
    tools?: any[];
    toolChoice?: ToolChoice;
    currentQuery?: string;
  }): Promise<LLMResponse> {
    return await this.sendRequest(options);
  }
}
